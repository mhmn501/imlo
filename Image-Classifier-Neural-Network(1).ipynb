{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create DataFrame from Iris dataset\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Add target column to DataFrame\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Convert target column to float\n",
    "df['target'] = df['target'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesssing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target variable from DataFrame\n",
    "x = df.drop('target', axis=1).values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom neural network class\n",
    "class My_NN(nn.Module):\n",
    "    \"\"\"\n",
    "    A custom neural network class.\n",
    "\n",
    "    Attributes:\n",
    "        in_feature (int): Number of input features.\n",
    "        hidden_layers (list): List specifying the number of neurons in each hidden layer.\n",
    "        out_features (int): Number of output features (or classes).\n",
    "        activation_function (function): Activation function to be used in hidden layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_feature, hidden_layers, out_features, activation_function = F.relu):\n",
    "        \"\"\"\n",
    "        Constructor method for initializing the neural network architecture.\n",
    "\n",
    "        Args:\n",
    "            in_feature (int): Number of input features.\n",
    "            hidden_layers (list): List specifying the number of neurons in each hidden layer.\n",
    "            out_features (int): Number of output features (or classes).\n",
    "            activation_function (function, optional): Activation function to be used in hidden layers (default is ReLU).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if len(hidden_layers) < 1:\n",
    "            raise Exception(\"My_NN must have at least 1 hidden layer\")\n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Linear(in_feature, hidden_layers[0]))\n",
    "        self.add_modules(\"input_layer\", self.layers[0])\n",
    "\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            self.layers.append(nn.Linear(hidden_layers[i-1], hidden_layers[i]))\n",
    "            self.add_module(f\"hidden_layer_{i}\", self.layers[i])\n",
    "\n",
    "        self.out = nn.Linear(hidden_layers[-1], out_features)\n",
    "\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.activation_function(self.layers[i](x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of the custom neural network\n",
    "classifier = My_NN(in_feature=4, hidden_layers=[16, 8], out_features=3, activation_function = F.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Train and Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split and format dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors datatype\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set training parameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "lossFn =  nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer with classifier parameters and learning rate\n",
    "optimizer = torch.optimzer.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Define number of epochs\n",
    "epochs = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the losses in each epoch\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for i in range(epochs):\n",
    "    y_pred = classifier.forward(x_train)\n",
    "\n",
    "    loss = lossFn(y_pred, y_train)\n",
    "\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch {i} - {loss}\")\n",
    "\n",
    "    optimizer.zero_grad() #calculates the differentials that we need\n",
    "    loss.backward() #output of loss fn, calculate how much correction (how to correct each neuron off given the loss we have)\n",
    "    optimizer.step() #sends it back through the network, the steps for the optimizer makes one step towards optimizing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the loss over epochs\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "with torch.no_grad():\n",
    "    y_eval = classifier.forward(x_test)\n",
    "    loss = lossFn(y_eval, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the final loss\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.plot([epochs], [loss], \"g+\") # Green cross indicates final loss\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
