{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from PyTorch\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "# Import necessary modules for Neural Network\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom Convolution Neural Network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_channels=3, num_out_ch=[32, 64, 128, 256], dropout=0.5, num_neurons=1024, num_classes=102):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.layer1 = nn.Sequential( #This is technically not a type of layer but it helps in combining different operations that are part of the same step\n",
    "            nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0], kernel_size=3, stride=1, padding=1), # Applies a 2D convolution over an input image composed of several input planes\n",
    "            nn.BatchNorm2d(num_out_ch[0]), # This applies batch normalization to the output from the convolutional layer\n",
    "            nn.ReLU() # Activation function is used to introduce nonlinearity in a neural network, helping mitigate the vanishing gradient problem during machine learning model training and enabling neural networks to learn more complex relationships in data\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[0], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Max pooling layer: down-sample an image by applying max filer to subregion\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[1]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[1], out_channels=num_out_ch[1], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[1], out_channels=num_out_ch[2], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[2]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[2], out_channels=num_out_ch[2], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[2]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[2], out_channels=num_out_ch[2], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[2], out_channels=num_out_ch[3], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[3]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[3], out_channels=num_out_ch[3], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[3]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[3], out_channels=num_out_ch[3], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[3], out_channels=num_out_ch[3], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[3]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[3], out_channels=num_out_ch[3], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[3]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_out_ch[3], out_channels=num_out_ch[3], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_out_ch[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout), # Dropout layer to prevent overfitting\n",
    "            nn.Linear(7*7*num_out_ch[3], num_neurons), # Performs a matrix multiplication of the input data with the weight matrix and adding the bias term\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    # Defines the forward pass of the network, where input data x is passed through each layer sequentially.\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Training Parameters, Device, Model, Optimizer, and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "NUM_OUT_CH = [32, 64, 128, 256]\n",
    "NUM_NEURONS = 1024\n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 8\n",
    "NUM_EPOCHS = 3000  # Number of training epochs\n",
    "LR = 0.001\n",
    "WEIGHT_DECAY = 0.001\n",
    "STEP_SIZE = 1000\n",
    "FACTOR = 0.9\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create an instance of the CNN model\n",
    "model = CNN(num_channels=3, num_out_ch=NUM_OUT_CH, dropout=DROPOUT, num_neurons=NUM_NEURONS, num_classes=102).to(device)  # 102 classes for Flowers102 dataset\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=FACTOR, patience=STEP_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprosessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224),  # Randomly crop and resize the image\n",
    "    transforms.RandomHorizontalFlip(),   # Randomly flip the image horizontally\n",
    "    transforms.RandomVerticalFlip(),   # Randomly flip the image Vertically\n",
    "    transforms.RandomRotation(10),       # Randomly rotate the image by up to 10 degrees\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),  # Randomly adjust brightness, contrast, saturation\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True), # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),              # Resize the image to 256x256\n",
    "    transforms.CenterCrop(224),          # Crop the center of the image to 224x224\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True), # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "test_transform = val_transform\n",
    "\n",
    "# Define dataset root directory\n",
    "data_dir = 'dataset_flower102/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to the dataset during data loading\n",
    "train_dataset = datasets.Flowers102(root=data_dir, split='train', transform=train_transform, download=True)\n",
    "valid_dataset = datasets.Flowers102(root=data_dir, split='val', transform=val_transform, download=True)\n",
    "test_dataset = datasets.Flowers102(root=data_dir, split='test', transform=test_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally resume from the best trained model along with training and validation loss values, as well as optimizer and scheduler current state\n",
    "resume_from_best_checkpoint = False\n",
    "if resume_from_best_checkpoint:\n",
    "    checkpoint = torch.load('latest_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    train_loss_history = checkpoint['train_loss']\n",
    "    val_loss_history = checkpoint['val_loss']\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    best_val_loss = float('inf')  # Initialize the best validation loss with a large value\n",
    "    \n",
    "\n",
    "print(\"best_val_loss: \", best_val_loss)\n",
    "\n",
    "patience = 50  # Number of epochs to wait before stopping if validation loss doesn't improve\n",
    "\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    \n",
    "    # Train the model\n",
    "    model.train() # Set the model to training mode\n",
    "    running_train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device) # Move images and labels to GPU\n",
    "\n",
    "        outputs = model.forward(images) # Forward pass\n",
    "        loss = loss_fn(outputs, labels) # Calculate the loss\n",
    "\n",
    "        optimizer.zero_grad() # Zero the parameter gradients\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Optimize\n",
    "\n",
    "        running_train_loss += loss.item() * images.size(0) #  scalar value of the loss tensor for the current batch * the batch size to account for the loss per sample in the batch\n",
    "        _, predicted = outputs.max(1) # Returns a tuple containing the maximum value along the specified dimension (class probabilities for each sample in the batch) and index of the max value\n",
    "        total += labels.size(0) # Accumulates the total number of sample seen during training\n",
    "        correct += predicted.eq(labels).sum().item() # Accumulates the total number of correct predictions over all batches.\n",
    "    \n",
    "    # Calculate training loss and accuracy\n",
    "    train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy = 100.0 * correct / total\n",
    "\n",
    "    # Print training loss and accuracy\n",
    "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device) # Move images and labels to GPU\n",
    "\n",
    "            outputs = model.forward(images)  # Forward pass\n",
    "            loss = loss_fn(outputs, labels)  # Calculate the loss\n",
    "\n",
    "            running_val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "    # Calculate validation loss and accuracy\n",
    "    val_loss = running_val_loss / len(valid_loader.dataset)\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_accuracy = 100.0 * correct / total\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Print validation loss and accuracy\n",
    "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "    # Check if validation loss has improved\n",
    "    if val_loss < best_val_loss:\n",
    "        print(\"Creating new checkpoint for best model...\")\n",
    "        best_val_loss = val_loss\n",
    "        patience = 50  # Reset patience if validation loss improves\n",
    "\n",
    "        # Save the best trained model along with training and validation loss values\n",
    "        torch.save({\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss_history,\n",
    "            'val_loss': val_loss_history, \n",
    "            'best_val_loss': best_val_loss\n",
    "        }, 'best_model.pth')\n",
    "\n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0:\n",
    "            print(\"Early stopping...\")\n",
    "            break\n",
    "\n",
    "# save the completed model training\n",
    "finish_model_state = model.state_dict()\n",
    "torch.save({\n",
    "    'model_state': finish_model_state,\n",
    "    'optimizer_state': optimizer.state_dict(),\n",
    "    'scheduler_state': scheduler.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'train_loss': train_loss_history,\n",
    "    'val_loss': val_loss_history,\n",
    "    'best_val_loss': best_val_loss\n",
    "}, 'latest_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "checkpoint = torch.load('latest_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "running_test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device) # Move images and labels to GPU\n",
    "\n",
    "        outputs = model.forward(images)  # Forward pass\n",
    "        loss = loss_fn(outputs, labels)  # Calculate the loss\n",
    "\n",
    "        running_test_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "# Calculate validation loss and accuracy\n",
    "test_loss = running_test_loss / len(test_loader.dataset)\n",
    "test_accuracy = 100.0 * correct / total\n",
    "\n",
    "# Print validation loss and accuracy\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 102])\n"
     ]
    }
   ],
   "source": [
    "# Visualize the network model\n",
    "# import torch\n",
    "# from torchviz import make_dot\n",
    "\n",
    "# # Ensure model is in evaluation mode for inference (since you're not training)\n",
    "# model.eval()\n",
    "\n",
    "# # Create a dummy input tensor of the correct size\n",
    "# dummy_input = torch.randn(1, 3, 224, 224)  # Adjust the size according to your input dimensions\n",
    "\n",
    "# # Check if CUDA is available and move the tensor to GPU if it is\n",
    "# if torch.cuda.is_available():\n",
    "#     dummy_input = dummy_input.to('cuda')\n",
    "\n",
    "# # Forward pass through the model\n",
    "# output = model(dummy_input)\n",
    "\n",
    "# print(output.shape)\n",
    "\n",
    "# # Generate the graph\n",
    "# dot = make_dot(output, params=dict(list(model.named_parameters()) + [('input', dummy_input)]))\n",
    "# dot.format = 'svg'\n",
    "# dot.render('network_architecture_enhanced', format='svg', engine='dot')\n",
    "# dot.attr('graph', fontsize='10', nodesep='0.5', ranksep='0.75')\n",
    "# dot.attr('node', shape='box', style='filled', fillcolor='lightblue', fontsize='12')\n",
    "# dot.attr('edge', fontsize='10', penwidth='2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
